<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Horned Sungem Documentation</title>
    <link>https://hornedsungem.github.io/Docs/</link>
    <description>Recent content on Horned Sungem Documentation</description>
    <generator>Hugo -- gohugo.io</generator>
    
	<atom:link href="https://hornedsungem.github.io/Docs/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Face detector</title>
      <link>https://hornedsungem.github.io/Docs/workflow/detector/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://hornedsungem.github.io/Docs/workflow/detector/</guid>
      <description>SSD-Mobilenet Face Detector This chapter will introduce how to use HS to deploy SSD-Mobilenet face detector
 Based on Ubuntu 16.04  Path and files  Python: SungemSDK/examples/python/FaceDetector.py Model file: SungemSDK/examples/graphs/graph_face_SSD  Face Detector Under python directory, enter following command to run face detector demo:
~/SungemSDK/examples/python$ python3 FaceDetector.py  get result:
| ======= Horned Sungem ======== | | Device found [0] | | ../graphs/graph_face_SSD | | Model loaded to Python | | Model allocated to device | | ============================== | * *****SSD [0]: Box values****** * .</description>
    </item>
    
    <item>
      <title>Object Detector</title>
      <link>https://hornedsungem.github.io/Docs/workflow/detector_object/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://hornedsungem.github.io/Docs/workflow/detector_object/</guid>
      <description>SSD-Mobilenet Object Detector This chapter will introduce how to user HS to deploy SSD-Mobilenet object detector.
Detector analyse images and find the target image location and size.
 Based on Ubuntu 16.04  Path and files  Python: SungemSDK/examples/python/ObjectDetector.py Model files: SungemSDK/examples/graphs/graph_object_SSD  Object Detector Under python directory, enter following command to run object detector demo:
~/SungemSDK/examples/python$ python3 ObjectDetector.py  Object detector is very similar to the previous face detector, except the number of classes is 20 (from VOC dataset).</description>
    </item>
    
    <item>
      <title>Scene Recorder</title>
      <link>https://hornedsungem.github.io/Docs/workflow/recorder/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://hornedsungem.github.io/Docs/workflow/recorder/</guid>
      <description>Scene Recorder This chapter introduces how to use HS to deploy GoogleNet for building a useful scene recorder tool
Introduction HS Scene Recorder records and classifies images in real-time. It &amp;lsquo;descripts&amp;rsquo; images into image feature vectors and store them into different bins for training a classifier. For instance, put HS in front of a door and record the images to bin-0 when door is closed and bin-&amp;lsquo;1&amp;rsquo; when door is opened.</description>
    </item>
    
    <item>
      <title>Face recorder (Working with two HS devices)</title>
      <link>https://hornedsungem.github.io/Docs/workflow/face_recognition/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://hornedsungem.github.io/Docs/workflow/face_recognition/</guid>
      <description>Face detetor + Scene recorder = Face recorder This chapter introduces how to build a face recorder with two HS devices.
 Note that two HS devices are needed to run this demo Tested on Ubuntu 16.04 system  Path and files  Face recorder Python：SungemSDK/examples/python/FaceRecorder.py Model file - detection：SungemSDK/examples/graphs/graph_face_SSD Model file - recognition：SungemSDK/examples/graphs/graph_face_rec  Image Recognition After connecting two HS devices, run face recorder with the following command under python directory</description>
    </item>
    
    <item>
      <title>Image Recogniser (Low-level API Tutorial)</title>
      <link>https://hornedsungem.github.io/Docs/workflow/image_recognition/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://hornedsungem.github.io/Docs/workflow/image_recognition/</guid>
      <description>SqueezeNet 1000 Classes Image Classifier This chapter introduces how to build an image classifier by using low-level API only.
 Tested on Ubuntu 16.04  Path and files  Python：SungemSDK/examples/python/ImageRecognition.py Model file：SungemSDK/examples/graphs/graph_sz  Image Recognition run image recogniser with the following command under python directory
~/SungemSDK/examples/python$ python3 ImageRecognition.py  The region-of-interest is highlighted with a cyan bounding box. You can adjust the size by pressing &amp;lsquo;w&amp;rsquo; and &amp;rsquo;s&amp;rsquo;.
Get Top5 classification result, as shown in the example.</description>
    </item>
    
    <item>
      <title>Rapiro Robot</title>
      <link>https://hornedsungem.github.io/Docs/workflow/rapiro/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://hornedsungem.github.io/Docs/workflow/rapiro/</guid>
      <description>This chapter introduced how to build a robot that controlled by HS face detector.
 Hardware requirement:
 Horned Sungem Device Raspberry Pi 3b Rapiro Robot 12V to 5V DC-DC module (Optional) Cooling fan (Optional)   Workflow The built-in model Mobilenet-SSD face detector is used in this DIY demo. The logic is illustrated as below:
Implementation Firstly assemble and power the Rapiro robot, then use robot to supply the power to a Raspeberry Pi.</description>
    </item>
    
    <item>
      <title>Smart Lamp</title>
      <link>https://hornedsungem.github.io/Docs/workflow/smartlamp/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://hornedsungem.github.io/Docs/workflow/smartlamp/</guid>
      <description>Here we give a tutorial on how to control a lamp through face detector with HS device. The lamb automatically turns on if face appears, otherwise turn off.
 Hardware list:
 HS device Raspberry Pi 3b 1 channel relay module 5V USB lamp   Workflow The built-in model Mobilenet-SSD face detector is used in this DIY demo. The logic is illustrated as below:
then we control the switch of the lamp through a 1 channel relay module.</description>
    </item>
    
    <item>
      <title>Sitting posture alarm</title>
      <link>https://hornedsungem.github.io/Docs/workflow/sitting_pose/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://hornedsungem.github.io/Docs/workflow/sitting_pose/</guid>
      <description>In this tutorial we will build a simple sitting posture alarm.
 Hardware list:
 HS device Raspberry Pi 3b Buzzer   Workflow Since currently the HS model zoo does not include pose estimation model, we simplify the problem and use our Scene Recorder to achieve the goal.
Here we consider two senarios that need to be distinguished:
 Normal sitting posture Unhealthy sitting posture  as shown below:</description>
    </item>
    
    <item>
      <title>Raspberry Pi Toy Car</title>
      <link>https://hornedsungem.github.io/Docs/workflow/raspi_car/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://hornedsungem.github.io/Docs/workflow/raspi_car/</guid>
      <description>We bring a HS enhanced Raspberry Pi Toy car by using object detector.
 Hardware list:
 HS device Raspberry Pi 3b Assembled Raspberry Pi toy car with SCM controlled motors   Workflow The built-in model Mobilenet-SSD object detector is used in this DIY demo. The logic is illustrated as below:
Implementation Firstly we assemble the toy car, the car is not necessary to be the same as ours, it should work as long as it is controlled through GPIO pin.</description>
    </item>
    
    <item>
      <title>Hello 2018</title>
      <link>https://hornedsungem.github.io/Docs/workflow/android/android_hello2018/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://hornedsungem.github.io/Docs/workflow/android/android_hello2018/</guid>
      <description>快速开始 下面介绍如何在Android Studio开发环境下通过角蜂鸟SDK使用卷积神经网络，实现复杂计算
步骤1：准备环境  下载最新版HornedSungemSDK jar包 请确保满足一下开发环境要求  确保minSdkVersion在Android 3.1以上 确保设备支持OTG Android Studio 2.0或以上版本  新建project工程 请确保在使用角蜂鸟相关功能及服务前，已阅读Android API,详见API文档  步骤2：添加SDK  将下载的软件包根据实际需求拷贝到您项目对应的文件夹里，例如：  该lib下包含了horned-sungemSDK及javacv所需要的jar和so库
注意：libs文件夹路径不能包含中文，否则会编译失败
2.请在build.gradle文件里，请将上述库放入正确路径下，如检索不到，可手动添加引用：
步骤3：添加权限 为了保证SDK正常运行，需要在AndroidManistest.xml文件下添加下列许可：
&amp;lt;uses-permission android:name=&amp;quot;android.permission.READ_EXTERNAL_STORAGE&amp;quot;/&amp;gt; &amp;lt;uses-permission android:name=&amp;quot;android.permission.WRITE_EXTERNAL_STORAGE&amp;quot;/&amp;gt; &amp;lt;uses-permission android:name=&amp;quot;android.hardware.usb.host&amp;quot;/&amp;gt; &amp;lt;uses-permission android:name=&amp;quot;android.hardware.usb.accessory&amp;quot;/&amp;gt; &amp;lt;uses-feature android:name=&amp;quot;android.hardware.usb.host&amp;quot;/&amp;gt;  步骤4：代码实现 下面通过一个简单hello2018的例子讲解具体怎么使用角蜂鸟SDK
 下载graph_mnist文件和4张测试图片,在您的module下新建assets包，将下载的文件复制到该目录下，如图：  定义HelloActivity继承HsBaseActivity,用于角蜂鸟通信和显示结果,具体代码如下：
public class HelloActivity extends HsBaseActivity { private TextView mTextView; private Handler mHandler = new Handler() { @Override public void handleMessage(Message msg) { super.handleMessage(msg); mTextView.</description>
    </item>
    
    <item>
      <title>人脸检测</title>
      <link>https://hornedsungem.github.io/Docs/workflow/android/android_face_detector/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://hornedsungem.github.io/Docs/workflow/android/android_face_detector/</guid>
      <description>本文主要给大家介绍如何在Android平台下使用角蜂鸟加载SSD-Mobilenet,实现人脸检测
准备工作  配置环境等详情请参照HELLO 2018里的快速开始，此处不具体阐述 下载物体检测所需模型graph_face_SSD文件，在您Android Studio中，当前module下新建assets包，将下载的模型文件复制到该目录下 因工程需要处理图像，所以使用了javacv库，可从GitHub自行下载或点击链接从示例工程中拷贝到自己工程下  具体实现  实现具体步骤：  将graph文件传输到角蜂鸟里  int status = allocateGraphByAssets(&amp;quot;graph_face_SSD&amp;quot;);  获取graph里的图像  byte[] bytes = mHsApi.getImage(STD, MEAN, zoom);  获取返回的处理结果  float[] result = mHsApi.getResult(0);  结果显示在view上  HornedSungemFrame frame = (HornedSungemFrame) msg.obj; if (frame != null) { mImageView.setImageBitmap(frame.getBitmap()); ArrayList&amp;lt;HornedSungemFrame.ObjectInfo&amp;gt; objectInfos = frame.getObjectInfos(); if (objectInfos != null &amp;amp;&amp;amp; objectInfos.size() &amp;gt; 0) { mDrawView.update(objectInfos); } else { mDrawView.removeRect(); } }   注意事项：  处理image图像区别：如果zoom为ture,获取的图像是640*360的BGR图像，如果zoom为false，获取的图像为1920*1080的图像，图像的排序需要注意，1080P的是BGR每个通道的数据传完才会传下个通道的。具体处理示例代码如下：    opencv_core.</description>
    </item>
    
    <item>
      <title>物体检测</title>
      <link>https://hornedsungem.github.io/Docs/workflow/android/android_object_detector/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://hornedsungem.github.io/Docs/workflow/android/android_object_detector/</guid>
      <description>本文主要给大家介绍下如何在Android平台下使用角蜂鸟加载SSD-Mobilenet，实现物体检测，本文里使用的模型支持20种物体检测
准备工作  配置环境等详情请参照HELLO 2018里的快速开始，此处不具体阐述 下载物体检测所需模型graph_object_SSD文件，在您Android Studio中，当前module下新建assets包，将下载的模型文件复制到该目录下 因工程需要处理图像，所以使用了javacv库，可从GitHub自行下载或点击链接从示例工程中拷贝到自己工程下  具体实现  本文体验的模型文件提供的20种物体检测包含：  String[] labels = {&amp;quot;aeroplane&amp;quot;, &amp;quot;bicycle&amp;quot;, &amp;quot;bird&amp;quot;, &amp;quot;boat&amp;quot;, &amp;quot;bottle&amp;quot;, &amp;quot;bus&amp;quot;, &amp;quot;car&amp;quot;, &amp;quot;cat&amp;quot;, &amp;quot;chair&amp;quot;, &amp;quot;cow&amp;quot;, &amp;quot;diningtable&amp;quot;, &amp;quot;dog&amp;quot;, &amp;quot;horse&amp;quot;, &amp;quot;motorbike&amp;quot;, &amp;quot;person&amp;quot;, &amp;quot;pottedplant&amp;quot;, &amp;quot;sheep&amp;quot;, &amp;quot;sofa&amp;quot;, &amp;quot;train&amp;quot;, &amp;quot;tvmonitor&amp;quot;};  主要实现流程：  将graph文件传输到角蜂鸟里 获取graph里的图像 获取返回的处理结果 结果显示在view上  主要业务逻辑代码如图：  int status = allocateGraphByAssets(&amp;quot;graph_object_SSD&amp;quot;); if (status != HsConnectApi.HS_OK) { Message message = mHandler.obtainMessage(); message.arg1 = 1; message.obj = status; mHandler.sendMessage(message); return; } while (true) { if (mHsApi !</description>
    </item>
    
    <item>
      <title>手绘识别</title>
      <link>https://hornedsungem.github.io/Docs/workflow/android/android_sketchguess/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://hornedsungem.github.io/Docs/workflow/android/android_sketchguess/</guid>
      <description>本文主要给大家介绍下在Android平台下使用角蜂鸟实现手绘识别功能
准备工作  配置环境等详情请参照HELLO 2018里的快速开始，此处不具体阐述 下载物体检测所需模型graph_sg文件，在您Android Studio中，当前module下新建assets包，将下载的模型文件复制到该目录下 因工程需要处理图像，所以使用了javacv库，可从GitHub自行下载或点击链接从示例工程中libs下拷贝到自己工程 将class_list_chn.txt文件拷贝到Android设备的存储空间下，用于物体比对  具体实现  将graph文件传输到角蜂鸟里  int status = allocateGraphByAssets(&amp;quot;graph_sg&amp;quot;);  读取物体分类文件   try { BufferedReader bufferedReader = new BufferedReader(new FileReader(Environment.getExternalStorageDirectory().getAbsolutePath() + &amp;quot;/hs/class_list_chn.txt&amp;quot;)); for (int i = 0; i &amp;lt; 345; i++) { String line = bufferedReader.readLine(); if (line != null) { String[] strings = line.split(&amp;quot; &amp;quot;); mObjectNames[i] = strings[0]; } } bufferedReader.close(); } catch (FileNotFoundException e) { e.printStackTrace(); Log.e(&amp;quot;SketchGuessThread&amp;quot;, &amp;quot;FileNotFoundException&amp;quot;); } catch (IOException e) { e.</description>
    </item>
    
    <item>
      <title>Low Level API</title>
      <link>https://hornedsungem.github.io/Docs/api/lowlevel/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://hornedsungem.github.io/Docs/api/lowlevel/</guid>
      <description>Horned Sungem Low Level API Version 0.1.0 Enumerations GlobalOption  Version: 0.1.0
 Overview:
The GlobalOption class is an enumeration class that defines the options that are passed to and received from the SetGlobalOption and the GetGlobalOption functions.
 enum: LOGLEVEL
 option type: int
 possible values: 0, 1, 2
 get/set get, set
 Description
0 = Nothing is printed (default)
1 = Print errors only
2 = Verbose</description>
    </item>
    
    <item>
      <title>High-level API</title>
      <link>https://hornedsungem.github.io/Docs/api/highlevel/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://hornedsungem.github.io/Docs/api/highlevel/</guid>
      <description>Horned Sungem High Level API Version 0.1.0 HS.__init__()  Version: 0.1.0
 Overview: initialisation
 Syntax:
  hs.HS(modelName, **kwargs)   Parameters:
 modelName: built-in models&amp;rsquo; name
 **kwargs key arguments: (Optional)
 &amp;lsquo;verbose&amp;rsquo; Detail of log. From 0 to 2: no log, key log, full log. Default is 2
 &amp;lsquo;mean&amp;rsquo; Mean value in preprocessing. Default is 1.0
 &amp;lsquo;scale&amp;rsquo; Scale value in preprocessing. Default is 0.007843 (1&amp;frasl;127.</description>
    </item>
    
    <item>
      <title>Android Java API (Chinese)</title>
      <link>https://hornedsungem.github.io/Docs/api/android/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://hornedsungem.github.io/Docs/api/android/</guid>
      <description>SungemSDK Android API Version 0.1.0 HsThread类相关函数及属性 当前类是跟角蜂鸟交互的子线程，开发者可继承该类进行功能扩展
类内主要变量： - mHandler:用于处理线程中的消息循环，通知主线程执行UI的更新 - mActivity:当前线程绑定的activity,可用于跳转，获取资源等 - mHsApi:与角蜂鸟通信的主要api类，可调用类里对应函数执行相应操作  相关函数  allocateGraph(filename) ：此函数是传送一个神经网络模型给角蜂鸟，通过加载该模型来实现某个功能
 参数 Parameters： filename（String类型） 文件绝对路径
 返回 return:返回操作状态 （状态声明都在HsConnectApi里） HS_OK值为0，表示成功 HS_ERROR值为-2，表示加载失败 HS_UNSUPPORTED_GRAPH_FILE值为-10,表示不支持的模型文件 HS_NO_FILE值为-12，表示filename路径有误，没有文件 Example用法:  int status=allocateGraph(Environment.getExternalStorageDirectory().getAbsolutePath() + &#34;/hs/&#34; + &#34;graph_face_SSD&#34;);  allocateGraphByAssets(filename) :与上述方法功能相似，区别在于参数表示在android工程assets包下的文件
 Example用法:  int status = allocateGraphByAssets(&amp;ldquo;graph_face_SSD&amp;rdquo;); 
 close(): 线程关闭时调用，执行操作包括：deallocate模型,关闭角蜂鸟设备等
 无参数 Example：示例代码   if (mHsThread != null) { mHsThread.setRunning(false); mHsThread.close(); }  setZoom( zoom)：设置获取角蜂鸟的图像分辨率大小，用于处理得到数据，设置图像宽高等</description>
    </item>
    
    <item>
      <title></title>
      <link>https://hornedsungem.github.io/Docs/_footer/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://hornedsungem.github.io/Docs/_footer/</guid>
      <description>Horned Sungem Documentation</description>
    </item>
    
    <item>
      <title></title>
      <link>https://hornedsungem.github.io/Docs/workflow/ocr/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://hornedsungem.github.io/Docs/workflow/ocr/</guid>
      <description> 本章为您介绍如何使用角蜂鸟在Python调用内置部署的OCR中文文字检测与识别。
OCR分析图片找出文字并识别。
 本教程基于Ubuntu 16.04系统  路径和文件  OCR Python：SungemSDK/examples/python/OCR.py 模型文件：SungemSDK/examples/graphs/graph_ocr  </description>
    </item>
    
  </channel>
</rss>